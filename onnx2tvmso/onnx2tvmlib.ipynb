{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# onnx to tvmlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导出动态库(PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/tvm/python/tvm/target/target.py:460: UserWarning: tvm.target.create() is being deprecated. Please use tvm.target.Target() instead\n",
      "  warnings.warn(\"tvm.target.create() is being deprecated. Please use tvm.target.Target() instead\")\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('dense_nopack.x86', ('TENSOR', (1, 1280), 'float32'), ('TENSOR', (1000, 1280), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 320, 7, 7), 'float32'), ('TENSOR', (1280, 320, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (320, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (960, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 160, 7, 7), 'float32'), ('TENSOR', (960, 160, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (160, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 576, 7, 7), 'float32'), ('TENSOR', (160, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 96, 14, 14), 'float32'), ('TENSOR', (576, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (96, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (96, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (384, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 64, 14, 14), 'float32'), ('TENSOR', (384, 64, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (64, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 192, 14, 14), 'float32'), ('TENSOR', (64, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 32, 28, 28), 'float32'), ('TENSOR', (192, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (32, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 144, 28, 28), 'float32'), ('TENSOR', (32, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 24, 56, 56), 'float32'), ('TENSOR', (144, 24, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (24, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 96, 56, 56), 'float32'), ('TENSOR', (24, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 96, 112, 112), 'float32'), ('TENSOR', (96, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 16, 112, 112), 'float32'), ('TENSOR', (96, 16, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 32, 112, 112), 'float32'), ('TENSOR', (16, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 32, 112, 112), 'float32'), ('TENSOR', (32, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 3, 224, 224), 'float32'), ('TENSOR', (32, 3, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: legacy graph runtime behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_runtime.GraphModule for the  new recommended usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output model files\n"
     ]
    }
   ],
   "source": [
    "# 导入onnx，转换成*.so动态库\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "\n",
    "#开始同样是读取.onnx模型\n",
    "onnx_model = onnx.load('../models/mobilenetv2.onnx')  # 导入模型\n",
    "\n",
    "# 以下的图片读取仅仅是为了测试\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "# # saving demo image, 存储个二进制文件\n",
    "# x.astype(\"float32\").tofile(\"./plane.bin\")\n",
    "# x.shape\n",
    "\n",
    "\n",
    "# 这里首先在PC的CPU上进行测试 所以使用LLVM进行导出\n",
    "target = tvm.target.create('llvm') # x86\n",
    "# target = tvm.target.arm_cpu(\"rasp3b\") # raspi\n",
    "# target = 'llvm'\n",
    "\n",
    "\n",
    "input_name = \"input.1\"  # 注意这里为之前导出onnx模型中的模型的输入id，这里为0\n",
    "shape_dict = {input_name: x.shape}\n",
    "# 利用Relay中的onnx前端读取我们导出的onnx模型\n",
    "sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 这里利用TVM构建出优化后模型的信息\n",
    "with relay.build_config(opt_level=2):\n",
    "    graph, lib, params = relay.build_module.build(sym, target, params=params)\n",
    "    \n",
    "\n",
    "    \n",
    "dtype = 'float32'\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "# 下面的函数导出我们需要的动态链接库 地址可以自己定义\n",
    "print(\"Output model files\")\n",
    "libpath = \"../models/mobilenet_pc.so\"\n",
    "lib.export_library(libpath)\n",
    "\n",
    "# 下面的函数导出我们神经网络的结构，使用json文件保存\n",
    "graph_json_path = \"../models/mobilenet_pc.json\"\n",
    "with open(graph_json_path, 'w') as fo:\n",
    "    fo.write(graph)\n",
    "\n",
    "# 下面的函数中我们导出神经网络模型的权重参数\n",
    "param_path = \"../models/mobilenet_pc.params\"\n",
    "with open(param_path, 'wb') as fo:\n",
    "    fo.write(relay.save_param_dict(params))\n",
    "# -------------至此导出模型阶段已经结束--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.使用python部署*.so文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "404\n",
      "Time elapsed is 0m 35s\n"
     ]
    }
   ],
   "source": [
    "# 使用python部署*.so文件\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "libpath = \"../models/mobilenet_pc.so\"\n",
    "graph_json_path = \"../models/mobilenet_pc.json\"\n",
    "param_path = \"../models/mobilenet_pc.params\"\n",
    "\n",
    "# 接下来我们加载导出的模型去测试导出的模型是否可以正常工作\n",
    "loaded_json = open(graph_json_path).read()\n",
    "loaded_lib = tvm.runtime.load_module(libpath)\n",
    "loaded_params = bytearray(open(param_path, \"rb\").read())\n",
    "\n",
    "# 这里执行的平台为CPU\n",
    "ctx = tvm.cpu()\n",
    "\n",
    "\n",
    "# 以下的图片读取仅仅是为了测试\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "\n",
    "\n",
    "\n",
    "module = graph_runtime.create(loaded_json, loaded_lib, ctx)\n",
    "module.load_params(loaded_params)\n",
    "module.set_input(\"input.1\", x)\n",
    "module.run()\n",
    "out_deploy = module.get_output(0).asnumpy()\n",
    "print(type(out_deploy))\n",
    "print(out_deploy.argmax())\n",
    "# print(out_deploy)\n",
    "\n",
    "# 输出tvm运行的时间\n",
    "since = time.time()\n",
    "for i in range(4000):\n",
    "    module.run()\n",
    "time_elapsed = time.time() - since\n",
    "print('Time elapsed is {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 导出动态库(rasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=llvm -keys=arm_cpu,cpu -device=arm_cpu -link-params=0 -mattr=+neon -model=bcm2837 -mtriple=armv7l-linux-gnueabihf, workload=('dense_nopack.x86', ('TENSOR', (1, 1280), 'float32'), ('TENSOR', (1000, 1280), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: DeprecationWarning: legacy graph runtime behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_runtime.GraphModule for the  new recommended usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output model files\n"
     ]
    }
   ],
   "source": [
    "# 导入onnx，转换成*.so动态库\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "\n",
    "#开始同样是读取.onnx模型\n",
    "onnx_model = onnx.load('../models/mobilenetv2.onnx')  # 导入模型\n",
    "\n",
    "# 以下的图片读取仅仅是为了测试\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "\n",
    "\n",
    "\n",
    "# 这里首先在PC的CPU上进行测试 所以使用LLVM进行导出\n",
    "# target = tvm.target.create('llvm') # x86\n",
    "target = tvm.target.arm_cpu(\"rasp3b\") # raspi\n",
    "# target = 'llvm'\n",
    "\n",
    "\n",
    "input_name = \"input.1\"  # 注意这里为之前导出onnx模型中的模型的输入id，这里为0\n",
    "shape_dict = {input_name: x.shape}\n",
    "# 利用Relay中的onnx前端读取我们导出的onnx模型\n",
    "sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 这里利用TVM构建出优化后模型的信息\n",
    "with relay.build_config(opt_level=2):\n",
    "    graph, lib, params = relay.build_module.build(sym, target, params=params)\n",
    "    \n",
    "\n",
    "    \n",
    "dtype = 'float32'\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "# 下面的函数导出我们需要的动态链接库 地址可以自己定义\n",
    "print(\"Output model files\")\n",
    "libpath = \"../models/mobilenet_rasp.so\"\n",
    "lib.export_library(libpath, cc=\"/usr/bin/arm-linux-gnueabihf-g++\")\n",
    "\n",
    "# 下面的函数导出我们神经网络的结构，使用json文件保存\n",
    "graph_json_path = \"../models/mobilenet_rasp.json\"\n",
    "with open(graph_json_path, 'w') as fo:\n",
    "    fo.write(graph)\n",
    "\n",
    "# 下面的函数中我们导出神经网络模型的权重参数\n",
    "param_path = \"../models/mobilenet_rasp.params\"\n",
    "with open(param_path, 'wb') as fo:\n",
    "    fo.write(relay.save_param_dict(params))\n",
    "# -------------至此导出模型阶段已经结束--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.导出so库（GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: legacy graph runtime behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_runtime.GraphModule for the  new recommended usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output model files\n"
     ]
    }
   ],
   "source": [
    "# 导入onnx，转换成*.so动态库\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "\n",
    "#开始同样是读取.onnx模型\n",
    "onnx_model = onnx.load('../models/mobilenetv2.onnx')  # 导入模型\n",
    "\n",
    "# 以下的图片读取仅仅是为了测试\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "\n",
    "\n",
    "\n",
    "# 这里首先在PC的CPU上进行测试 所以使用LLVM进行导出\n",
    "# target = tvm.target.create('llvm') # x86\n",
    "# target = tvm.target.arm_cpu(\"rasp3b\") # raspi\n",
    "# target = 'llvm'\n",
    "target = tvm.target.cuda()\n",
    "\n",
    "\n",
    "input_name = \"input.1\"  # 注意这里为之前导出onnx模型中的模型的输入id，这里为0\n",
    "shape_dict = {input_name: x.shape}\n",
    "# 利用Relay中的onnx前端读取我们导出的onnx模型\n",
    "sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 这里利用TVM构建出优化后模型的信息\n",
    "with relay.build_config(opt_level=2):\n",
    "    graph, lib, params = relay.build_module.build(sym, target, params=params)\n",
    "    \n",
    "\n",
    "    \n",
    "dtype = 'float32'\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "# 下面的函数导出我们需要的动态链接库 地址可以自己定义\n",
    "print(\"Output model files\")\n",
    "libpath = \"../models/mobilenet_gpu.so\"\n",
    "lib.export_library(libpath)\n",
    "\n",
    "# 下面的函数导出我们神经网络的结构，使用json文件保存\n",
    "graph_json_path = \"../models/mobilenet_gpu.json\"\n",
    "with open(graph_json_path, 'w') as fo:\n",
    "    fo.write(graph)\n",
    "\n",
    "# 下面的函数中我们导出神经网络模型的权重参数\n",
    "param_path = \"../models/mobilenet_gpu.params\"\n",
    "with open(param_path, 'wb') as fo:\n",
    "    fo.write(relay.save_param_dict(params))\n",
    "# -------------至此导出模型阶段已经结束--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
