{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deploy with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.使用python部署*.so文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用python部署*.so文件\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "libpath = \"../models/mobilenet_pc.so\"\n",
    "graph_json_path = \"../models/mobilenet_pc.json\"\n",
    "param_path = \"../models/mobilenet_pc.params\"\n",
    "\n",
    "# 接下来我们加载导出的模型去测试导出的模型是否可以正常工作\n",
    "loaded_json = open(graph_json_path).read()\n",
    "loaded_lib = tvm.runtime.load_module(libpath)\n",
    "loaded_params = bytearray(open(param_path, \"rb\").read())\n",
    "\n",
    "# 以下的图片读取仅仅是为了测试\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "\n",
    "\n",
    "# 这里执行的平台为CPU\n",
    "ctx = tvm.cpu()\n",
    "# ctx = tvm.gpu(0)\n",
    "dtype = 'float32'\n",
    "\n",
    "module = graph_runtime.create(loaded_json, loaded_lib, ctx) # 加载模型\n",
    "module.load_params(loaded_params)\n",
    "module.set_input(\"input.1\", x)\n",
    "module.run()\n",
    "out_deploy = module.get_output(0).asnumpy()\n",
    "print(type(out_deploy))\n",
    "print(out_deploy.argmax())\n",
    "# print(out_deploy)\n",
    "\n",
    "# 输出tvm运行的时间\n",
    "since = time.time()\n",
    "for i in range(4000):\n",
    "    module.run()\n",
    "time_elapsed = time.time() - since\n",
    "print('Time elapsed is {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.使用python部署so （GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, workload=('dense_small_batch.cuda', ('TENSOR', (1, 1280), 'float32'), ('TENSOR', (1000, 1280), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: DeprecationWarning: legacy graph runtime behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_runtime.GraphModule for the  new recommended usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output model files\n"
     ]
    }
   ],
   "source": [
    "# 导入onnx，转换成*.so动态库\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "#开始同样是读取.onnx模型\n",
    "onnx_model = onnx.load('../models/mobilenetv2.onnx')  # 导入模型\n",
    "\n",
    "# -------以下的图片读取仅仅是为了测试-----\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "# -------------end---------------\n",
    "\n",
    "\n",
    "#  ----------------import model into tvm from mxnet---------------\n",
    "input_name = \"input.1\"  # 注意这里为之前导出onnx模型中的模型的输入id，这里为0\n",
    "shape_dict = {input_name: x.shape}\n",
    "# 利用Relay中的onnx前端读取我们导出的onnx模型\n",
    "sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "# -----------------end-----------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------这里首先在PC的GPU上进行测试 所以使用LLVM进行导出----------\n",
    "# 设定目标硬件为 GPU，生成TVM模型\n",
    "## ---------------------------- \n",
    "# graph：execution graph in json format\n",
    "# lib: tvm module library of compiled functions for the graph on the target hardware\n",
    "# params: parameter blobs\n",
    "## ---------------------------\n",
    "target = 'cuda'\n",
    "# target = tvm.target.create('llvm') # x86\n",
    "# target = tvm.target.arm_cpu(\"rasp3b\") # raspi\n",
    "# target = 'llvm'\n",
    "\n",
    "# with relay.build_config(opt_level=3):\n",
    "#     graph, lib, params = relay.build(relay_func, target, params=relay_params)\n",
    "\n",
    "# 这里利用TVM构建出优化后模型的信息\n",
    "with relay.build_config(opt_level=2):\n",
    "    graph, lib, params = relay.build(sym, target, params=params)\n",
    "#     graph, lib, params = relay.build_module.build(sym, target, params=params)\n",
    "# ------------\n",
    "\n",
    "# ----------------推理 with GPU （PYTHON）------\n",
    "# libpath = \"../models/mobilenet_cuda.so\"\n",
    "# graph_json_path = \"../models/mobilenet_cuda.json\"\n",
    "# param_path = \"../models/mobilenet_cuda.params\"\n",
    "\n",
    "ctx = tvm.gpu(0)\n",
    "dtype = 'float32'\n",
    "module = graph_runtime.create(graph, lib, ctx)   # 加载模型\n",
    "# module.load_params(params)\n",
    "# module.set_input(\"input.1\", x)\n",
    "## set input data\n",
    "module.set_input('input.1', tvm.nd.array(x.astype(dtype)))\n",
    "## set input params\n",
    "module.set_input(**params)\n",
    "module.run()\n",
    "out_deploy = module.get_output(0).asnumpy()\n",
    "print(type(out_deploy))\n",
    "print(out_deploy.argmax())\n",
    "# print(out_deploy)\n",
    "\n",
    "# ## 加载模型\n",
    "# m = graph_runtime.create(graph, lib, ctx)\n",
    "# ## set input data\n",
    "# m.set_input('data', tvm.nd.array(x.astype(dtype)))\n",
    "# ## set input params\n",
    "# m.set_input(**params)\n",
    "# m.run()\n",
    "# # get output\n",
    "# outputs = m.get_output(0)\n",
    "# top1 = np.argmax(outputs.asnumpy()[0])\n",
    "\n",
    "# -----------------导出库--------\n",
    "# 下面的函数导出我们需要的动态链接库 地址可以自己定义\n",
    "print(\"Output model files\")\n",
    "libpath = \"../models/mobilenet_cuda.so\"\n",
    "lib.export_library(libpath)\n",
    "\n",
    "# 下面的函数导出我们神经网络的结构，使用json文件保存\n",
    "graph_json_path = \"../models/mobilenet_cuda.json\"\n",
    "with open(graph_json_path, 'w') as fo:\n",
    "    fo.write(graph)\n",
    "\n",
    "# 下面的函数中我们导出神经网络模型的权重参数\n",
    "param_path = \"../models/mobilenet_cuda.params\"\n",
    "with open(param_path, 'wb') as fo:\n",
    "    fo.write(relay.save_param_dict(params))\n",
    "# -------------至此导出模型阶段已经结束--------\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
