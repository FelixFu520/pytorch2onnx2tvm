{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch to ONNX\n",
    "将pytorch模型转成ONNX模型,并测试直接使用pytorch部署的时间\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入库包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from MobileNetV2 import mobilenet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 测试pytorch运行模型时间（4000次）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed is 1m 30s\n"
     ]
    }
   ],
   "source": [
    "# 获取pytorch模型，并输出运行时间\n",
    "model = mobilenet_v2(pretrained=True)\n",
    "example = torch.rand(1, 3, 224, 224)   \n",
    "\n",
    "# 输出pytorch运行的时间\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    since = time.time()\n",
    "    for i in range(4000):\n",
    "        model(example)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time elapsed is {:.0f}m {:.0f}s'.\n",
    "          format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. pytorch模型转换成ONNX模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1:150528, 3:50176, 224:224, 224:1, requires_grad=0, device=cpu),\n",
      "      %classifier.weight : Float(1000:1280, 1280:1, requires_grad=1, device=cpu),\n",
      "      %classifier.bias : Float(1000:1, requires_grad=1, device=cpu),\n",
      "      %468 : Float(32:27, 3:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %469 : Float(32:1, requires_grad=0, device=cpu),\n",
      "      %471 : Float(32:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %472 : Float(32:1, requires_grad=0, device=cpu),\n",
      "      %474 : Float(16:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %475 : Float(16:1, requires_grad=0, device=cpu),\n",
      "      %477 : Float(96:16, 16:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %478 : Float(96:1, requires_grad=0, device=cpu),\n",
      "      %480 : Float(96:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %481 : Float(96:1, requires_grad=0, device=cpu),\n",
      "      %483 : Float(24:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %484 : Float(24:1, requires_grad=0, device=cpu),\n",
      "      %486 : Float(144:24, 24:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %487 : Float(144:1, requires_grad=0, device=cpu),\n",
      "      %489 : Float(144:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %490 : Float(144:1, requires_grad=0, device=cpu),\n",
      "      %492 : Float(24:144, 144:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %493 : Float(24:1, requires_grad=0, device=cpu),\n",
      "      %495 : Float(144:24, 24:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %496 : Float(144:1, requires_grad=0, device=cpu),\n",
      "      %498 : Float(144:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %499 : Float(144:1, requires_grad=0, device=cpu),\n",
      "      %501 : Float(32:144, 144:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %502 : Float(32:1, requires_grad=0, device=cpu),\n",
      "      %504 : Float(192:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %505 : Float(192:1, requires_grad=0, device=cpu),\n",
      "      %507 : Float(192:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %508 : Float(192:1, requires_grad=0, device=cpu),\n",
      "      %510 : Float(32:192, 192:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %511 : Float(32:1, requires_grad=0, device=cpu),\n",
      "      %513 : Float(192:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %514 : Float(192:1, requires_grad=0, device=cpu),\n",
      "      %516 : Float(192:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %517 : Float(192:1, requires_grad=0, device=cpu),\n",
      "      %519 : Float(32:192, 192:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %520 : Float(32:1, requires_grad=0, device=cpu),\n",
      "      %522 : Float(192:32, 32:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %523 : Float(192:1, requires_grad=0, device=cpu),\n",
      "      %525 : Float(192:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %526 : Float(192:1, requires_grad=0, device=cpu),\n",
      "      %528 : Float(64:192, 192:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %529 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %531 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %532 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %534 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %535 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %537 : Float(64:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %538 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %540 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %541 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %543 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %544 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %546 : Float(64:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %547 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %549 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %550 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %552 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %553 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %555 : Float(64:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %556 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %558 : Float(384:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %559 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %561 : Float(384:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %562 : Float(384:1, requires_grad=0, device=cpu),\n",
      "      %564 : Float(96:384, 384:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %565 : Float(96:1, requires_grad=0, device=cpu),\n",
      "      %567 : Float(576:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %568 : Float(576:1, requires_grad=0, device=cpu),\n",
      "      %570 : Float(576:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %571 : Float(576:1, requires_grad=0, device=cpu),\n",
      "      %573 : Float(96:576, 576:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %574 : Float(96:1, requires_grad=0, device=cpu),\n",
      "      %576 : Float(576:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %577 : Float(576:1, requires_grad=0, device=cpu),\n",
      "      %579 : Float(576:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %580 : Float(576:1, requires_grad=0, device=cpu),\n",
      "      %582 : Float(96:576, 576:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %583 : Float(96:1, requires_grad=0, device=cpu),\n",
      "      %585 : Float(576:96, 96:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %586 : Float(576:1, requires_grad=0, device=cpu),\n",
      "      %588 : Float(576:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %589 : Float(576:1, requires_grad=0, device=cpu),\n",
      "      %591 : Float(160:576, 576:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %592 : Float(160:1, requires_grad=0, device=cpu),\n",
      "      %594 : Float(960:160, 160:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %595 : Float(960:1, requires_grad=0, device=cpu),\n",
      "      %597 : Float(960:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %598 : Float(960:1, requires_grad=0, device=cpu),\n",
      "      %600 : Float(160:960, 960:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %601 : Float(160:1, requires_grad=0, device=cpu),\n",
      "      %603 : Float(960:160, 160:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %604 : Float(960:1, requires_grad=0, device=cpu),\n",
      "      %606 : Float(960:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %607 : Float(960:1, requires_grad=0, device=cpu),\n",
      "      %609 : Float(160:960, 960:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %610 : Float(160:1, requires_grad=0, device=cpu),\n",
      "      %612 : Float(960:160, 160:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %613 : Float(960:1, requires_grad=0, device=cpu),\n",
      "      %615 : Float(960:9, 1:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %616 : Float(960:1, requires_grad=0, device=cpu),\n",
      "      %618 : Float(320:960, 960:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %619 : Float(320:1, requires_grad=0, device=cpu),\n",
      "      %621 : Float(1280:320, 320:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %622 : Float(1280:1, requires_grad=0, device=cpu)):\n",
      "  %467 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%input.1, %468, %469)\n",
      "  %317 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%467) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %470 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%317, %471, %472)\n",
      "  %320 : Float(1:401408, 32:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%470) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %473 : Float(1:200704, 16:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%320, %474, %475)\n",
      "  %476 : Float(1:1204224, 96:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%473, %477, %478)\n",
      "  %325 : Float(1:1204224, 96:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%476) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %479 : Float(1:301056, 96:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%325, %480, %481)\n",
      "  %328 : Float(1:301056, 96:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%479) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %482 : Float(1:75264, 24:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%328, %483, %484)\n",
      "  %485 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%482, %486, %487)\n",
      "  %333 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%485) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %488 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%333, %489, %490)\n",
      "  %336 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%488) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %491 : Float(1:75264, 24:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%336, %492, %493)\n",
      "  %339 : Float(1:75264, 24:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Add(%482, %491) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %494 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%339, %495, %496)\n",
      "  %342 : Float(1:451584, 144:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%494) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %497 : Float(1:112896, 144:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%342, %498, %499)\n",
      "  %345 : Float(1:112896, 144:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%497) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %500 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%345, %501, %502)\n",
      "  %503 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%500, %504, %505)\n",
      "  %350 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%503) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %506 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%350, %507, %508)\n",
      "  %353 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%506) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %509 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%353, %510, %511)\n",
      "  %356 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Add(%500, %509) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %512 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%356, %513, %514)\n",
      "  %359 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%512) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %515 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%359, %516, %517)\n",
      "  %362 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%515) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %518 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%362, %519, %520)\n",
      "  %365 : Float(1:25088, 32:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Add(%356, %518) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %521 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%365, %522, %523)\n",
      "  %368 : Float(1:150528, 192:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%521) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %524 : Float(1:37632, 192:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%368, %525, %526)\n",
      "  %371 : Float(1:37632, 192:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%524) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %527 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%371, %528, %529)\n",
      "  %530 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%527, %531, %532)\n",
      "  %376 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%530) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %533 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%376, %534, %535)\n",
      "  %379 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%533) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %536 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%379, %537, %538)\n",
      "  %382 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%527, %536) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %539 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%382, %540, %541)\n",
      "  %385 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%539) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %542 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%385, %543, %544)\n",
      "  %388 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%542) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %545 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%388, %546, %547)\n",
      "  %391 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%382, %545) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %548 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%391, %549, %550)\n",
      "  %394 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%548) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %551 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%394, %552, %553)\n",
      "  %397 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%551) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %554 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%397, %555, %556)\n",
      "  %400 : Float(1:12544, 64:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%391, %554) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %557 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%400, %558, %559)\n",
      "  %403 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%557) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %560 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%403, %561, %562)\n",
      "  %406 : Float(1:75264, 384:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%560) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %563 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%406, %564, %565)\n",
      "  %566 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%563, %567, %568)\n",
      "  %411 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%566) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %569 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%411, %570, %571)\n",
      "  %414 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%569) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %572 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%414, %573, %574)\n",
      "  %417 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%563, %572) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %575 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%417, %576, %577)\n",
      "  %420 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%575) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %578 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%420, %579, %580)\n",
      "  %423 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%578) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %581 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%423, %582, %583)\n",
      "  %426 : Float(1:18816, 96:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%417, %581) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %584 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%426, %585, %586)\n",
      "  %429 : Float(1:112896, 576:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%584) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %587 : Float(1:28224, 576:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%429, %588, %589)\n",
      "  %432 : Float(1:28224, 576:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%587) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %590 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%432, %591, %592)\n",
      "  %593 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%590, %594, %595)\n",
      "  %437 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%593) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %596 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%437, %597, %598)\n",
      "  %440 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%596) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %599 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%440, %600, %601)\n",
      "  %443 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Add(%590, %599) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %602 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%443, %603, %604)\n",
      "  %446 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%602) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %605 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%446, %606, %607)\n",
      "  %449 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%605) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %608 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%449, %609, %610)\n",
      "  %452 : Float(1:7840, 160:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Add(%443, %608) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:62:0\n",
      "  %611 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%452, %612, %613)\n",
      "  %455 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%611) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %614 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%455, %615, %616)\n",
      "  %458 : Float(1:47040, 960:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%614) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %617 : Float(1:15680, 320:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%458, %618, %619)\n",
      "  %620 : Float(1:62720, 1280:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%617, %621, %622)\n",
      "  %463 : Float(1:62720, 1280:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%620) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1186:0\n",
      "  %464 : Float(1:8960, 1280:7, 7:1, requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[3], keepdims=0](%463) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:110:0\n",
      "  %465 : Float(1:1280, 1280:1, requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2], keepdims=0](%464) # /root/pytorch2onnx2tvm/pytorch2onnx/MobileNetV2.py:110:0\n",
      "  %466 : Float(1:1000, 1000:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%465, %classifier.weight, %classifier.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1690:0\n",
      "  return (%466)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pytorch to onnx\n",
    "torch_out = torch.onnx.export(model,\n",
    "                              example,\n",
    "                              \"../models/mobilenetv2.onnx\",\n",
    "                              verbose=True,\n",
    "                              export_params=True   # 带参数输出\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.onnx转成tvm，并测试是否成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('dense_nopack.x86', ('TENSOR', (1, 1280), 'float32'), ('TENSOR', (1000, 1280), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 320, 7, 7), 'float32'), ('TENSOR', (1280, 320, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (320, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (960, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 160, 7, 7), 'float32'), ('TENSOR', (960, 160, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 960, 7, 7), 'float32'), ('TENSOR', (160, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 576, 7, 7), 'float32'), ('TENSOR', (160, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 96, 14, 14), 'float32'), ('TENSOR', (576, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (96, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (96, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (384, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 64, 14, 14), 'float32'), ('TENSOR', (384, 64, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 384, 14, 14), 'float32'), ('TENSOR', (64, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 192, 14, 14), 'float32'), ('TENSOR', (64, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 32, 28, 28), 'float32'), ('TENSOR', (192, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (32, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 144, 28, 28), 'float32'), ('TENSOR', (32, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 24, 56, 56), 'float32'), ('TENSOR', (144, 24, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (24, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 96, 56, 56), 'float32'), ('TENSOR', (24, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 96, 112, 112), 'float32'), ('TENSOR', (96, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 16, 112, 112), 'float32'), ('TENSOR', (96, 16, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 32, 112, 112), 'float32'), ('TENSOR', (16, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 32, 112, 112), 'float32'), ('TENSOR', (32, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('conv2d_NCHWc.x86', ('TENSOR', (1, 3, 224, 224), 'float32'), ('TENSOR', (32, 3, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 144, 56, 56), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 192, 28, 28), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (1, 576, 14, 14), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "# onnx to tvm , or test onnx model\n",
    "import onnx\n",
    "import time\n",
    "import tvm\n",
    "import numpy as np\n",
    "import tvm.relay as relay\n",
    "from PIL import Image\n",
    "\n",
    "onnx_model = onnx.load('../models/mobilenetv2.onnx')  # 导入模型\n",
    "\n",
    "mean = [123., 117., 104.]                   # 在ImageNet上训练数据集的mean和std\n",
    "std = [58.395, 57.12, 57.375]\n",
    "\n",
    "\n",
    "def transform_image(image):                # 定义转化函数，将PIL格式的图像转化为格式维度的numpy格式数组\n",
    "    image = image - np.array(mean)\n",
    "    image /= np.array(std)\n",
    "    image = np.array(image).transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :].astype('float32')\n",
    "    return image\n",
    "\n",
    "img = Image.open('../imgs/plane.png').resize((224, 224)) # 这里我们将图像resize为特定大小\n",
    "x = transform_image(img)\n",
    "# saving demo image, 存储个二进制文件\n",
    "x.astype(\"float32\").tofile(\"./plane.bin\")\n",
    "x.shape\n",
    "\n",
    "target = 'llvm'\n",
    "\n",
    "input_name = \"input.1\"  # 注意这里为之前导出onnx模型中的模型的输入id，这里为0\n",
    "shape_dict = {input_name: x.shape}\n",
    "# 利用Relay中的onnx前端读取我们导出的onnx模型\n",
    "sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "\n",
    "with relay.build_config(opt_level=3):\n",
    "    intrp = relay.build_module.create_executor('graph', sym, tvm.cpu(0), target)\n",
    "# with tvm.transform.PassContext(opt_level=3):\n",
    "#      intrp = relay.build_module.create_executor(\"graph\", sym, tvm.cpu(0), target)\n",
    "\n",
    "        \n",
    "dtype = 'float32'\n",
    "# func = intrp.evaluate(sym)\n",
    "func = intrp.evaluate()\n",
    "\n",
    "output = func(tvm.nd.array(x.astype(dtype)), **params).asnumpy()\n",
    "print(output.argmax())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
